"""
LaMa (Resolution-robust Large Mask Inpainting) å®ç°
åŸºäºå®˜æ–¹ advimman/lama å®ç°
æ”¯æŒ GPU (CUDA) å’Œ CPU
"""
import torch
import numpy as np
from PIL import Image
import os
from typing import Optional
import urllib.request
from pathlib import Path


class LamaInpaint:
    """LaMa Inpainting æ¨¡å‹"""
    
    MODEL_URL = "https://github.com/enesmsahin/simple-lama-inpainting/releases/download/v0.1.0/big-lama.pt"
    
    def __init__(self, model_path: Optional[str] = None, device: str = "cuda"):
        """
        åˆå§‹åŒ– LaMa Inpaint
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœä¸º None,ä½¿ç”¨é»˜è®¤è·¯å¾„
            device: 'cuda' æˆ– 'cpu'
        """
        # è®¾ç½®è®¾å¤‡
        if device == "cuda" and torch.cuda.is_available():
            self.device = torch.device("cuda")
            self.actual_device = "cuda"
            print(f"âœ“ ä½¿ç”¨ CUDA åŠ é€Ÿ (GPU: {torch.cuda.get_device_name(0)})")
        else:
            self.device = torch.device("cpu")
            self.actual_device = "cpu"
            print("âœ“ ä½¿ç”¨ CPU æ¨¡å¼")
        
        # ç¡®å®šæ¨¡å‹è·¯å¾„
        if model_path is None:
            current_dir = Path(__file__).parent.parent
            model_path = current_dir / "weights" / "big-lama.pt"
            model_path = str(model_path.resolve())
        
        self.model_path = model_path
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            raise FileNotFoundError(
                f"LaMa æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}\n"
                f"è¯·è¿è¡Œ: python backend/download_models.py"
            )
        
        # åŠ è½½æ¨¡å‹
        print(f"ğŸ“¦ åŠ è½½ LaMa æ¨¡å‹: {os.path.basename(model_path)}")
        try:
            self.model = torch.jit.load(model_path, map_location=self.device)
            self.model.eval()
            print("âœ“ LaMa æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            raise RuntimeError(f"LaMa æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def get_info(self) -> dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "name": "LaMa (Resolution-robust Large Mask Inpainting)",
            "device": self.actual_device,
            "model_path": self.model_path
        }
    
    @staticmethod
    def download_model(save_path: str) -> None:
        """
        ä¸‹è½½ LaMa é¢„è®­ç»ƒæ¨¡å‹
        
        Args:
            save_path: ä¿å­˜è·¯å¾„
        """
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        print(f"ğŸ“¥ ä¸‹è½½ LaMa æ¨¡å‹...")
        print(f"   URL: {LamaInpaint.MODEL_URL}")
        print(f"   ä¿å­˜åˆ°: {save_path}")
        
        try:
            urllib.request.urlretrieve(
                LamaInpaint.MODEL_URL,
                save_path,
                reporthook=lambda count, block_size, total_size: print(
                    f"\r   è¿›åº¦: {count * block_size / total_size * 100:.1f}%",
                    end=""
                ) if total_size > 0 else None
            )
            print("\nâœ“ æ¨¡å‹ä¸‹è½½å®Œæˆ")
        except Exception as e:
            raise RuntimeError(f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
    
    def inpaint(
        self, 
        image: Image.Image, 
        mask: Image.Image
    ) -> Image.Image:
        """
        æ‰§è¡Œ Inpaint ä¿®å¤
        
        Args:
            image: åŸå§‹å›¾ç‰‡(PIL Image, RGB)
            mask: é®ç½©å›¾ç‰‡(PIL Image, L/ç°åº¦, ç™½è‰²=éœ€è¦ä¿®å¤çš„åŒºåŸŸ)
            
        Returns:
            ä¿®å¤åçš„å›¾ç‰‡(PIL Image)
        """
        # è·å–åŸå§‹å°ºå¯¸
        orig_width, orig_height = image.size
        print(f"   LaMa Inpaint å¤„ç†: {orig_width}x{orig_height}")
        
        # è½¬æ¢ä¸º RGB
        if image.mode != 'RGB':
            image = image.convert('RGB')
        if mask.mode != 'L':
            mask = mask.convert('L')
        
        # è½¬æ¢ä¸º numpy æ•°ç»„
        img_array = np.array(image).astype(np.float32) / 255.0
        mask_array = np.array(mask).astype(np.float32) / 255.0
        
        # è½¬æ¢ä¸º torch tensor [1, 3, H, W]
        img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)
        mask_tensor = torch.from_numpy(mask_array).unsqueeze(0).unsqueeze(0)
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        img_tensor = img_tensor.to(self.device)
        mask_tensor = mask_tensor.to(self.device)
        
        print(f"   mask éé›¶åƒç´ : {(mask_array > 0.5).sum()}/{mask_array.size}")
        
        # æ¨ç†
        with torch.no_grad():
            # LaMa æ¨¡å‹è¾“å…¥: image å’Œ mask
            output = self.model(img_tensor, mask_tensor)
        
        # è½¬æ¢å› numpy
        output_np = output.squeeze(0).permute(1, 2, 0).cpu().numpy()
        
        # è½¬æ¢å› [0, 255]
        output_np = np.clip(output_np * 255.0, 0, 255).astype(np.uint8)
        
        # è½¬æ¢ä¸º PIL Image
        result_image = Image.fromarray(output_np, mode='RGB')
        
        # ç¡®ä¿å°ºå¯¸æ­£ç¡®
        if result_image.size != (orig_width, orig_height):
            result_image = result_image.resize((orig_width, orig_height), Image.LANCZOS)
        
        print(f"   LaMa Inpaint å®Œæˆ")
        
        return result_image
