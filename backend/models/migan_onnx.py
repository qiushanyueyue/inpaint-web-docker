"""
MI-GAN ONNX Runtime Inpaint æ¨¡å‹
ä½¿ç”¨ ONNX Runtime åœ¨åç«¯è¿è¡Œ,æ”¯æŒ GPU (CUDA) å’Œ CPU
"""
import onnxruntime as ort
import numpy as np
from PIL import Image
from typing import Tuple


class MIGANONNXModel:
    """MI-GAN Inpaint æ¨¡å‹(ONNX Runtime å®ç°)"""
    
    def __init__(self, model_path: str, device: str = "cuda"):
        """
        åˆå§‹åŒ– ONNX æ¨¡å‹
        
        Args:
            model_path: ONNX æ¨¡å‹æ–‡ä»¶è·¯å¾„
            device: 'cuda' æˆ– 'cpu'
        """
        # é…ç½® execution providers
        providers = []
        if device == "cuda":
            available_providers = ort.get_available_providers()
            if "CUDAExecutionProvider" in available_providers:
                providers.append("CUDAExecutionProvider")
                print("âœ“ ä½¿ç”¨ CUDA åŠ é€Ÿ")
            else:
                print("âš ï¸  CUDA ä¸å¯ç”¨,é™çº§åˆ° CPU")
        
        providers.append("CPUExecutionProvider")
        
        # åŠ è½½æ¨¡å‹
        self.session = ort.InferenceSession(model_path, providers=providers)
        self.actual_device = "cuda" if "CUDAExecutionProvider" in self.session.get_providers() else "cpu"
        
        print(f"âœ“ MI-GAN ONNX æ¨¡å‹åŠ è½½æˆåŠŸ (è®¾å¤‡: {self.actual_device})")
        
    def get_info(self) -> dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "name": "MI-GAN (ONNX)",
            "device": self.actual_device,
            "providers": self.session.get_providers()
        }
    
    def inpaint(
        self, 
        image: Image.Image, 
        mask: Image.Image
    ) -> Image.Image:
        """
        æ‰§è¡Œ Inpaint ä¿®å¤
        
        Args:
            image: åŸå§‹å›¾ç‰‡(PIL Image, RGB)
            mask: é®ç½©å›¾ç‰‡(PIL Image, L/ç°åº¦,ç™½è‰²=éœ€è¦ä¿®å¤çš„åŒºåŸŸ)
            
        Returns:
            ä¿®å¤åçš„å›¾ç‰‡(PIL Image)
        """
        # è·å–åŸå§‹å°ºå¯¸
        orig_width, orig_height = image.size
        
        # æ¨¡å‹éœ€è¦å›ºå®š 512x512 è¾“å…¥
        MODEL_SIZE = 512
        
        # 1. Resize å›¾ç‰‡å’Œé®ç½©åˆ° 512x512
        image_resized = image.resize((MODEL_SIZE, MODEL_SIZE), Image.LANCZOS)
        mask_resized = mask.resize((MODEL_SIZE, MODEL_SIZE), Image.LANCZOS)
        print(f"   åŸå§‹å°ºå¯¸: {orig_width}x{orig_height} -> ç¼©æ”¾åˆ°: {MODEL_SIZE}x{MODEL_SIZE}")
        
        # 2. é¢„å¤„ç†å›¾ç‰‡
        img_array = self._preprocess_image(image_resized)
        
        # 3. é¢„å¤„ç†é®ç½©
        mask_array = self._preprocess_mask(mask_resized, (MODEL_SIZE, MODEL_SIZE))
        
        # 4. æ£€æŸ¥æ¨¡å‹è¾“å…¥æ ¼å¼
        input_names = [inp.name for inp in self.session.get_inputs()]
        input_shapes = [inp.shape for inp in self.session.get_inputs()]
        print(f"ğŸ“Š ONNX æ¨¡å‹è¾“å…¥ä¿¡æ¯: {len(input_names)} ä¸ªè¾“å…¥")
        for i, (name, shape) in enumerate(zip(input_names, input_shapes)):
            print(f"   è¾“å…¥ {i}: name='{name}', shape={shape}")
        
        # 5. ONNX æ¨ç† - æ ¹æ®æ¨¡å‹è¾“å…¥æ•°é‡å¤„ç†
        if len(input_names) >= 2:
            # åŒè¾“å…¥æ¨¡å‹: åˆ†åˆ«ä¼ å…¥ image å’Œ mask
            print(f"   ä½¿ç”¨åŒè¾“å…¥æ¨¡å¼: {input_names[0]}=image, {input_names[1]}=mask")
            outputs = self.session.run(
                None,
                {
                    input_names[0]: img_array,
                    input_names[1]: mask_array
                }
            )
        else:
            # å•è¾“å…¥æ¨¡å‹: å°† image å’Œ mask æ²¿é€šé“æ‹¼æ¥
            # MI-GAN åŸå§‹æ¨¡å‹æœŸæœ› [1, 4, 512, 512] è¾“å…¥ (RGB + mask)
            print(f"   ä½¿ç”¨å•è¾“å…¥æ¨¡å¼: å°† image å’Œ mask æ²¿é€šé“æ‹¼æ¥")
            
            # å°† image è½¬ä¸º float [0, 1]
            img_float = img_array.astype(np.float32) / 255.0
            
            # mask_array å½¢çŠ¶æ˜¯ [1, 1, H, W]
            # æ³¨æ„ï¼šmask ä¸­ç™½è‰²(255)=éœ€è¦ä¿®å¤çš„åŒºåŸŸï¼Œè½¬ä¸º 1.0
            # ä¸åè½¬ï¼Œç›´æ¥å½’ä¸€åŒ–
            mask_channel = mask_array.astype(np.float32) / 255.0
            
            # æ‹¼æ¥
            combined = np.concatenate([img_float, mask_channel], axis=1)
            print(f"   æ‹¼æ¥åå½¢çŠ¶: {combined.shape}")
            print(f"   image èŒƒå›´: [{img_float.min():.2f}, {img_float.max():.2f}]")
            print(f"   mask èŒƒå›´: [{mask_channel.min():.2f}, {mask_channel.max():.2f}]")
            
            outputs = self.session.run(
                None,
                {input_names[0]: combined}
            )
        
        # 6. åå¤„ç†
        output = outputs[0]
        print(f"   æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}, èŒƒå›´: [{output.min():.3f}, {output.max():.3f}]")
        
        # æ£€æŸ¥è¾“å‡ºæ˜¯å¦æ˜¯ float [0,1] æ ¼å¼
        if output.max() <= 1.0:
            print(f"   è¾“å‡ºæ ¼å¼: float [0,1]ï¼Œä¹˜ä»¥ 255")
            output = output * 255.0
        
        result_image = self._postprocess(output, MODEL_SIZE, MODEL_SIZE)
        
        # 7. Resize å›åŸå§‹å°ºå¯¸
        result_image = result_image.resize((orig_width, orig_height), Image.LANCZOS)
        print(f"   è¾“å‡ºå°ºå¯¸: {result_image.size}")
        
        return result_image
    
    def _preprocess_image(self, image: Image.Image) -> np.ndarray:
        """
        é¢„å¤„ç†å›¾ç‰‡
        è½¬æ¢ä¸º ONNX æ¨¡å‹éœ€è¦çš„æ ¼å¼: [1, 3, H, W], uint8
        """
        # ç¡®ä¿æ˜¯ RGB
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # è½¬æ¢ä¸º numpy æ•°ç»„: [H, W, 3]
        img_np = np.array(image, dtype=np.uint8)
        
        # è½¬ç½®ä¸º [3, H, W]
        img_np = img_np.transpose(2, 0, 1)
        
        # æ·»åŠ  batch ç»´åº¦: [1, 3, H, W]
        img_np = np.expand_dims(img_np, axis=0)
        
        return img_np
    
    def _preprocess_mask(
        self, 
        mask: Image.Image, 
        target_size: Tuple[int, int]
    ) -> np.ndarray:
        """
        é¢„å¤„ç†é®ç½©
        è½¬æ¢ä¸º ONNX æ¨¡å‹éœ€è¦çš„æ ¼å¼: [1, 1, H, W], uint8
        """
        # è°ƒæ•´å¤§å°åˆ°ä¸å›¾ç‰‡ç›¸åŒ
        if mask.size != target_size:
            mask = mask.resize(target_size, Image.LANCZOS)
        
        # ç¡®ä¿æ˜¯ç°åº¦å›¾
        if mask.mode != 'L':
            mask = mask.convert('L')
        
        # è½¬æ¢ä¸º numpy æ•°ç»„: [H, W]
        mask_np = np.array(mask, dtype=np.uint8)
        
        # æ·»åŠ  channel å’Œ batch ç»´åº¦: [1, 1, H, W]
        mask_np = np.expand_dims(mask_np, axis=0)
        mask_np = np.expand_dims(mask_np, axis=0)
        
        return mask_np
    
    def _postprocess(
        self, 
        output: np.ndarray, 
        width: int, 
        height: int
    ) -> Image.Image:
        """
        åå¤„ç†è¾“å‡º
        å°† ONNX è¾“å‡ºè½¬æ¢ä¸º PIL Image
        
        Args:
            output: ONNX è¾“å‡º [1, 3, H, W], uint8
            width: ç›®æ ‡å®½åº¦
            height: ç›®æ ‡é«˜åº¦
        """
        # ç§»é™¤ batch ç»´åº¦: [3, H, W]
        img_np = output.squeeze(0)
        
        # è½¬ç½®å› [H, W, 3]
        img_np = img_np.transpose(1, 2, 0)
        
        # ç¡®ä¿æ˜¯ uint8
        img_np = np.clip(img_np, 0, 255).astype(np.uint8)
        
        # è½¬æ¢ä¸º PIL Image
        result = Image.fromarray(img_np, mode='RGB')
        
        # ç¡®ä¿å°ºå¯¸æ­£ç¡®
        if result.size != (width, height):
            result = result.resize((width, height), Image.LANCZOS)
        
        return result
